# Arquivo: backend/app.py (Vers√£o Final: Gemini API)

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import requests
import os 
import json

# --- Configura√ß√µes da Aplica√ß√£o ---
app = Flask(__name__) 
CORS(app) 

# --- Vari√°veis de Ambiente ---
PORT = int(os.environ.get("PORT", 5001))

# üîë CHAVE: A chave de API do Gemini ser√° lida no Render.
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY") 

# Modelo e Endpoint
GEMINI_MODEL = "gemini-2.5-flash"
# O endpoint usa a chave como um par√¢metro de consulta (Query Parameter)
GEMINI_API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"


# --- Rotas da Aplica√ß√£o ---

@app.route('/')
def serve_index():
    """
    Rota que serve o arquivo index.html, que est√° dentro da pasta 'static' no container.
    """
    return send_from_directory(app.static_folder, 'index.html')

@app.route('/api/ask', methods=['POST'])
def ask_ai_agent():
    """
    Recebe uma pergunta, envia para a LexAI e retorna a resposta.
    """
    data = request.get_json()
    prompt = data.get('prompt')

    if not prompt:
        return jsonify({"error": "Prompt n√£o fornecido"}), 400

    if not GEMINI_API_KEY:
        return jsonify({"error": "Erro: Vari√°vel GEMINI_API_KEY n√£o configurada no Render."}), 500
        
    print(f"Recebendo prompt: '{prompt}'")

    # Payload no formato da Gemini API
    payload = {
        "contents": [{
            "parts": [{"text": prompt}]
        }],
        "generationConfig": {
            "temperature": 0.7,
            # üí° CORRE√á√ÉO AQUI: Aumentando o limite m√°ximo de tokens para 4096.
            "maxOutputTokens": 4096 
        }
    }

    response = None

    try:
        # Envia a requisi√ß√£o para a Gemini API
        response = requests.post(
            GEMINI_API_URL, 
            json=payload,
            timeout=60
        )
        
        response.raise_for_status() # Lan√ßar exce√ß√£o para status 4xx ou 5xx
        
        gemini_response = response.json()
        
        # Extrair o texto gerado (com acesso seguro)
        candidates = gemini_response.get('candidates')
        
        if candidates:
            content = candidates[0].get('content', {})
            parts = content.get('parts', [])
            
            if parts and parts[0].get('text'):
                full_response = parts[0]['text']
            else:
                 # Se n√£o houver texto gerado, checa o motivo (finishReason)
                reason = candidates[0].get('finishReason', 'Motivo Desconhecido')
                full_response = (
                    f"Desculpe, a IA parou de gerar texto (Motivo: {reason}). "
                    "Isso pode ocorrer por filtros de seguran√ßa ou o prompt ser muito longo. Tente outra pergunta."
                )
        else:
            full_response = f"Desculpe, o Agente LexAI n√£o retornou candidatos de resposta (falha no servi√ßo). Detalhes: {str(gemini_response)}"
        
        print(f"Resposta obtida com sucesso do modelo {GEMINI_MODEL}.")

        return jsonify({"answer": full_response})

    except requests.exceptions.RequestException as e:
        # --- Tratamento de Erros de Comunica√ß√£o ---
        error_details = "Erro de comunica√ß√£o ou rede."
        status_code = "Desconhecido"
        
        if response is not None:
             status_code = response.status_code
             try:
                 error_details = response.json().get('error', {}).get('message', 'Erro desconhecido da API.')
             except:
                 error_details = response.text

        error_msg = f"Houve um problema de comunica√ß√£o com o Agente LexAI (Status {status_code}). Detalhes: {error_details}"
        
        print(f"ERRO DE REQUISI√á√ÉO IA: {e}")
        return jsonify({"error": error_msg}), 500
    except Exception as e:
        print(f"Erro inesperado: {e}")
        return jsonify({"error": f"Erro interno no servidor: {e}"}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=PORT, debug=True)
